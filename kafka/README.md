# Kafka

## Содержание
1. [Введение в Kafka](#введение-в-kafka)
2. [Основные концепции](#основные-концепции)
3. [Архитектура Kafka](#архитектура-kafka)
4. [Производители и потребители](#производители-и-потребители)
5. [Топики и партиции](#топики-и-партиции)
6. [Группы потребителей](#группы-потребителей)
7. [Kafka Streams](#kafka-streams)
8. [Конфигурация и развертывание](#конфигурация-и-развертывание)
9. [Типичные сценарии использования](#типичные-сценарии-использования)
10. [Вопросы на собеседовании](#вопросы-на-собеседовании)

## Введение в Kafka

Apache Kafka — это распределенная платформа потоковой передачи данных, которая позволяет публиковать, хранить и обрабатывать потоки записей в режиме реального времени. Kafka была разработана LinkedIn и позже стала проектом Apache Software Foundation.

### Ключевые особенности Kafka:
- **Высокая пропускная способность**: может обрабатывать миллионы сообщений в секунду
- **Низкая задержка**: задержка до миллисекунд
- **Отказоустойчивость**: данные реплицируются между несколькими узлами
- **Масштабируемость**: легко масштабируется горизонтально
- **Долговечность**: сообщения сохраняются на диске и реплицируются
- **Распределенность**: работает как кластер на нескольких серверах

## Основные концепции

### Сообщение (Message)
Базовая единица данных в Kafka. Сообщение состоит из ключа, значения, временной метки и опциональных метаданных.

### Топик (Topic)
Категория или канал, в который публикуются сообщения. Топики могут иметь множество производителей и потребителей.

### Партиция (Partition)
Топики разделены на партиции для параллельной обработки. Каждая партиция представляет собой упорядоченную последовательность сообщений.

### Смещение (Offset)
Уникальный идентификатор сообщения в партиции. Смещение увеличивается последовательно для каждого нового сообщения.

### Брокер (Broker)
Сервер Kafka, который хранит данные и обслуживает клиентов. Кластер Kafka состоит из нескольких брокеров.

### Производитель (Producer)
Клиент, который публикует сообщения в топики Kafka.

### Потребитель (Consumer)
Клиент, который подписывается на топики и обрабатывает сообщения.

### Группа потребителей (Consumer Group)
Группа потребителей, которые совместно обрабатывают сообщения из топиков.

### ZooKeeper
Сервис координации, используемый Kafka для управления кластером (в новых версиях Kafka зависимость от ZooKeeper постепенно устраняется).

## Архитектура Kafka

### Кластерная архитектура
Kafka работает как кластер из одного или нескольких серверов (брокеров). Кластер Kafka хранит потоки записей в категориях, называемых топиками.

```
                   +-------------+
                   |  ZooKeeper  |
                   +------+------+
                          |
                          v
+----------+     +--------+-------+     +-----------+
| Producer | --> | Kafka Cluster  | <-- | Consumer  |
+----------+     | (Brokers)      |     +-----------+
                 +----------------+
```

### Роль брокеров
Каждый брокер управляет определенным набором партиций и обрабатывает запросы на запись и чтение для этих партиций. Брокеры также управляют репликацией данных для обеспечения отказоустойчивости.

### Репликация данных
Для обеспечения отказоустойчивости каждая партиция может быть реплицирована на несколько брокеров. Один из брокеров выступает в роли лидера для партиции, а остальные — в роли последователей.

```
Broker 1          Broker 2          Broker 3
+--------+        +--------+        +--------+
|Topic A |        |Topic A |        |Topic A |
|Part 0  |<-------|Part 0  |<-------|Part 0  |
|(Leader)|        |(Follower)       |(Follower)
+--------+        +--------+        +--------+
|Topic B |        |Topic B |        |Topic B |
|Part 1  |<-------|Part 1  |<-------|Part 1  |
|(Follower)       |(Leader)|        |(Follower)
+--------+        +--------+        +--------+
```

## Производители и потребители

### Производители (Producers)
Производители публикуют сообщения в топики. Они могут выбирать, в какую партицию отправить сообщение, используя ключ сообщения или пользовательскую стратегию разделения.

```java
// Пример кода производителя на Java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
ProducerRecord<String, String> record = new ProducerRecord<>("my-topic", "key", "value");
producer.send(record);
producer.close();
```

### Потребители (Consumers)
Потребители читают сообщения из топиков. Они отслеживают, какие сообщения были прочитаны, используя смещение (offset).

```java
// Пример кода потребителя на Java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "my-group");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

Consumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("my-topic"));

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("offset = %d, key = %s, value = %s%n", 
                          record.offset(), record.key(), record.value());
    }
}
```

## Топики и партиции

### Структура топика
Топик — это категория или канал, в который публикуются сообщения. Топики разделены на партиции для параллельной обработки.

### Партиционирование
Партиционирование позволяет распределить данные по нескольким брокерам и обрабатывать их параллельно. Количество партиций определяет максимальное количество потребителей, которые могут одновременно читать из топика в рамках одной группы.

```
Topic: "my-topic"
+----------------+
| Partition 0    |
| 0 1 2 3 4 5... |
+----------------+
| Partition 1    |
| 0 1 2 3 4 5... |
+----------------+
| Partition 2    |
| 0 1 2 3 4 5... |
+----------------+
```

### Стратегии партиционирования
- **Round-robin**: распределение сообщений по партициям по кругу
- **По ключу**: сообщения с одинаковым ключом всегда попадают в одну и ту же партицию
- **Пользовательская**: можно реализовать собственную стратегию партиционирования

## Группы потребителей

### Концепция групп потребителей
Группа потребителей — это набор потребителей, которые совместно обрабатывают сообщения из топиков. Каждая партиция обрабатывается только одним потребителем из группы.

```
Topic: "my-topic"
+----------------+     +----------------+
| Partition 0    |---->| Consumer 1     |
+----------------+     | (Group: "A")   |
                       +----------------+
+----------------+     +----------------+
| Partition 1    |---->| Consumer 2     |
+----------------+     | (Group: "A")   |
                       +----------------+
+----------------+     +----------------+
| Partition 2    |---->| Consumer 3     |
+----------------+     | (Group: "A")   |
                       +----------------+
```

### Балансировка нагрузки
Kafka автоматически балансирует партиции между потребителями в группе. Если потребитель добавляется или удаляется из группы, Kafka перераспределяет партиции.

### Отслеживание смещения
Группа потребителей отслеживает смещение (offset) для каждой партиции, чтобы знать, какие сообщения уже были обработаны.

## Kafka Streams

### Что такое Kafka Streams
Kafka Streams — это библиотека для обработки потоков данных в реальном времени. Она позволяет преобразовывать данные из одного топика в другой.

### Основные операции
- **Фильтрация**: отбор сообщений по условию
- **Отображение**: преобразование сообщений
- **Агрегация**: объединение сообщений
- **Соединение**: объединение данных из разных топиков

```java
// Пример Kafka Streams
StreamsBuilder builder = new StreamsBuilder();
KStream<String, String> source = builder.stream("input-topic");
KStream<String, String> transformed = source.map((key, value) -> KeyValue.pair(key, value.toUpperCase()));
transformed.to("output-topic");
```

### Состояние и хранилища состояний
Kafka Streams позволяет хранить состояние обработки в локальных хранилищах, которые реплицируются для обеспечения отказоустойчивости.

## Конфигурация и развертывание

### Основные настройки брокера
- `broker.id`: уникальный идентификатор брокера
- `log.dirs`: директории для хранения данных
- `zookeeper.connect`: адрес ZooKeeper
- `num.partitions`: количество партиций по умолчанию для новых топиков
- `log.retention.hours`: время хранения сообщений

### Настройки производителя
- `acks`: уровень подтверждения записи (0, 1, all)
- `batch.size`: размер пакета сообщений
- `linger.ms`: время ожидания перед отправкой неполного пакета
- `max.in.flight.requests.per.connection`: максимальное количество неподтвержденных запросов

### Настройки потребителя
- `group.id`: идентификатор группы потребителей
- `auto.offset.reset`: стратегия начала чтения (earliest, latest)
- `enable.auto.commit`: автоматическая фиксация смещения
- `max.poll.records`: максимальное количество записей за один опрос

### Развертывание в продакшн
- Рекомендуется минимум 3 брокера для обеспечения отказоустойчивости
- Репликация данных с фактором репликации не менее 3
- Мониторинг производительности и использования ресурсов
- Регулярное резервное копирование конфигурации

## Типичные сценарии использования

### Обработка событий в реальном времени
Kafka идеально подходит для сбора и обработки событий в реальном времени, таких как клики пользователей, действия в приложении, логи и метрики.

### Потоковая обработка данных
С помощью Kafka Streams или других инструментов (Apache Flink, Apache Spark) можно обрабатывать потоки данных в реальном времени.

### Интеграция систем
Kafka может служить центральным хабом для интеграции различных систем, обеспечивая асинхронное взаимодействие между ними.

### Хранение логов и аудит
Kafka может использоваться для централизованного хранения логов приложений и аудита действий пользователей.

### Микросервисная архитектура
В микросервисной архитектуре Kafka часто используется для асинхронного взаимодействия между сервисами.

## Вопросы на собеседовании

### Основные концепции Kafka

#### Что такое Apache Kafka и для чего она используется?
Apache Kafka — это распределенная платформа потоковой передачи данных, которая позволяет публиковать, хранить и обрабатывать потоки записей в режиме реального времени. Она используется для:
- Обработки событий в реальном времени
- Потоковой обработки данных
- Интеграции систем
- Хранения логов и аудита
- Асинхронного взаимодействия в микросервисной архитектуре

#### Какие основные компоненты входят в архитектуру Kafka?
- **Брокеры**: серверы, хранящие данные и обслуживающие клиентов
- **Топики**: категории или каналы для публикации сообщений
- **Партиции**: разделы топиков для параллельной обработки
- **Производители**: клиенты, публикующие сообщения
- **Потребители**: клиенты, читающие и обрабатывающие сообщения
- **ZooKeeper**: сервис координации для управления кластером

#### Что такое топик и партиция в Kafka?
**Топик** — это категория или канал, в который публикуются сообщения. Топики разделены на **партиции**, которые представляют собой упорядоченные последовательности сообщений. Партиционирование позволяет распределить данные по нескольким брокерам и обрабатывать их параллельно.

### Производители и потребители

#### Как работает производитель в Kafka?
Производитель публикует сообщения в топики. Процесс включает:
1. Сериализацию сообщения
2. Определение партиции (по ключу или стратегии)
3. Отправку сообщения брокеру
4. Получение подтверждения (в зависимости от настройки `acks`)

#### Как работает потребитель в Kafka?
Потребитель читает сообщения из топиков. Процесс включает:
1. Подписку на топики
2. Опрос новых сообщений
3. Десериализацию сообщений
4. Обработку сообщений
5. Фиксацию смещения (offset)

#### Что такое группа потребителей и как она работает?
Группа потребителей — это набор потребителей, которые совместно обрабатывают сообщения из топиков. Каждая партиция обрабатывается только одним потребителем из группы. Это позволяет масштабировать обработку данных горизонтально.

### Архитектура и производительность

#### Как Kafka обеспечивает высокую пропускную способность?
- Эффективное использование дисковых операций (последовательное чтение/запись)
- Партиционирование для параллельной обработки
- Пакетная обработка сообщений
- Zero-copy оптимизация при передаче данных
- Сжатие сообщений

#### Что такое репликация в Kafka и как она работает?
Репликация — это процесс копирования данных между брокерами для обеспечения отказоустойчивости. Каждая партиция может быть реплицирована на несколько брокеров. Один из брокеров выступает в роли лидера для партиции, а остальные — в роли последователей. Только лидер обрабатывает запросы на запись и чтение.

#### Что такое ISR (In-Sync Replicas) в Kafka?
ISR (In-Sync Replicas) — это набор реплик, которые синхронизированы с лидером партиции. Реплика считается синхронизированной, если она:
- Имеет активное соединение с ZooKeeper
- Регулярно отправляет запросы на получение новых сообщений от лидера
- Не отстает от лидера больше, чем на заданное значение

### Конфигурация и оптимизация

#### Какие настройки важны для обеспечения надежности доставки сообщений?
- `acks=all`: производитель получает подтверждение только после записи на все реплики
- Достаточный фактор репликации (обычно 3)
- `min.insync.replicas`: минимальное количество синхронизированных реплик для записи
- `enable.idempotence=true`: предотвращение дублирования сообщений
- Правильная настройка повторных попыток отправки

#### Как выбрать оптимальное количество партиций для топика?
При выборе количества партиций следует учитывать:
- Требуемую пропускную способность
- Количество потребителей в группе
- Доступные ресурсы брокеров
- Размер сообщений и объем данных

Общее правило: количество партиций должно быть не меньше количества потребителей в группе для максимального параллелизма.

#### Что такое компактные топики (compacted topics) и когда их использовать?
Компактные топики — это топики с политикой компактификации, которая сохраняет только последнее сообщение для каждого ключа. Они используются, когда важно только последнее состояние для каждого ключа, например:
- Для хранения конфигураций
- Для кэширования данных
- Для построения материализованных представлений

### Kafka Streams и интеграция

#### Что такое Kafka Streams и какие задачи оно решает?
Kafka Streams — это библиотека для обработки потоков данных в реальном времени. Она позволяет:
- Фильтровать, преобразовывать и агрегировать данные
- Соединять потоки данных из разных топиков
- Обрабатывать данные с сохранением состояния
- Создавать материализованные представления данных

#### Как Kafka интегрируется с другими системами обработки данных?
Kafka имеет богатую экосистему коннекторов для интеграции с различными системами:
- **Kafka Connect**: фреймворк для интеграции с внешними системами
- **Source Connectors**: для импорта данных из внешних систем в Kafka
- **Sink Connectors**: для экспорта данных из Kafka во внешние системы
- Интеграция с Apache Spark, Apache Flink, Apache Storm для сложной обработки данных

#### Какие паттерны проектирования часто используются с Kafka?
- **Event Sourcing**: хранение всех изменений состояния как последовательности событий
- **CQRS (Command Query Responsibility Segregation)**: разделение операций чтения и записи
- **Saga Pattern**: координация транзакций в распределенных системах
- **Dead Letter Queue**: обработка сообщений, которые не удалось обработать
- **Outbox Pattern**: обеспечение атомарности обновления базы данных и отправки сообщений

### Мониторинг и отладка

#### Какие метрики важно мониторить в Kafka?
- **Брокеры**: использование CPU, памяти, диска, сетевой трафик
- **Топики**: скорость записи/чтения, размер, количество сообщений
- **Производители**: скорость отправки, задержка, ошибки
- **Потребители**: скорость потребления, отставание (lag), ошибки
- **Репликация**: статус ISR, задержка репликации

#### Как диагностировать проблемы с производительностью в Kafka?
1. Проверить метрики брокеров и клиентов
2. Анализировать логи на наличие ошибок
3. Проверить конфигурацию на соответствие рекомендациям
4. Использовать инструменты мониторинга (Prometheus, Grafana)
5. Проверить отставание потребителей (consumer lag)
6. Анализировать использование ресурсов (CPU, память, диск, сеть)

#### Что такое отставание потребителя (consumer lag) и как его уменьшить?
Отставание потребителя — это разница между последним опубликованным смещением и текущим смещением потребителя. Большое отставание означает, что потребители не успевают обрабатывать сообщения.

Способы уменьшения отставания:
- Увеличить количество потребителей в группе
- Оптимизировать код обработки сообщений
- Увеличить количество партиций (если это возможно)
- Увеличить `max.poll.records` для получения большего количества сообщений за один опрос
- Масштабировать ресурсы для потребителей